# Generaci√≥n de im√°genes con IA ‚Äî Stable Diffusion + Ollama + Python

![Imagen generada con Stable Diffusion](101-Ejercicios/generated_images/hero-gesti√≥n-acad√©mica-moderna.png)

> üîó **GitHub Pages:** [https://mutenros.github.io/Sistemas-informaticos-001-Generacin-de-imgenes-con-IA/](https://mutenros.github.io/Sistemas-informaticos-001-Generacin-de-imgenes-con-IA/)

## Introducci√≥n

Este proyecto explora la **generaci√≥n de im√°genes con inteligencia artificial** utilizando el modelo **Stable Diffusion** y scripts en **Python**. El trabajo progresa desde la instalaci√≥n b√°sica del entorno hasta un pipeline automatizado completo que lee un archivo XML de producto, genera prompts inteligentes con **Ollama (LLaMA 3)** y produce im√°genes de marketing SaaS con Stable Diffusion.

El resultado es un sistema capaz de tomar una descripci√≥n de producto en formato XML y generar autom√°ticamente todas las im√°genes necesarias para una landing page, sin intervenci√≥n manual en la creaci√≥n de prompts ni en la generaci√≥n de las im√°genes.

---

## Desarrollo de las partes

### 1. Instalaci√≥n del entorno ‚Äî AUTOMATIC1111 y Stable Diffusion WebUI

El primer paso documenta c√≥mo instalar la interfaz web de Stable Diffusion (AUTOMATIC1111) en un sistema Linux. Se utiliza un entorno virtual de Python y se clona el repositorio oficial.

```bash
# 001-Instalar modelo de imagen.md ‚Äî l√≠neas 1-6
# Ruta: 101-Ejercicios/001-Instalar modelo de imagen.md
sudo apt update
sudo apt install -y git python3 python3-venv python3-pip

git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
cd stable-diffusion-webui
./webui.sh
```

Este archivo es la base de todo el proyecto: sin el modelo instalado, los scripts posteriores no pueden funcionar. AUTOMATIC1111 proporciona una interfaz gr√°fica web para generar im√°genes.

---

### 2. Instalaci√≥n de dependencias Python ‚Äî Diffusers y PyTorch

El segundo ejercicio documenta la instalaci√≥n de las librer√≠as Python necesarias para ejecutar Stable Diffusion desde c√≥digo (sin interfaz web). Usa `diffusers` de Hugging Face, `torch` con soporte CUDA para GPU, y `Pillow` para el tratamiento de im√°genes.

```bash
# 002-stable diffusion.md ‚Äî l√≠neas 1-8
# Ruta: 101-Ejercicios/002-stable diffusion.md
sudo apt install -y python3-venv git
python3 -m venv venv
source venv/bin/activate

pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install diffusers transformers accelerate safetensors pillow
```

Se instala PyTorch con soporte CUDA 12.1 para aprovechar la GPU en la generaci√≥n de im√°genes, lo que reduce el tiempo de generaci√≥n dr√°sticamente.

---

### 3. Generaci√≥n de una imagen simple ‚Äî Script b√°sico

El script `003-crear imagen.py` es el primer ejercicio pr√°ctico: genera una imagen a partir de un prompt de texto usando el pipeline de Stable Diffusion v1.5. Detecta autom√°ticamente si hay GPU disponible y ajusta la precisi√≥n (float16 para CUDA, float32 para CPU).

```python
# 003-crear imagen.py ‚Äî l√≠neas 15-26
# Ruta: 101-Ejercicios/003-crear imagen.py
device = "cuda" if torch.cuda.is_available() else "cpu"
dtype = torch.float16 if device == "cuda" else torch.float32
print(f"Dispositivo seleccionado: {device}")

try:
    pipe = StableDiffusionPipeline.from_pretrained(
        MODEL_ID,
        torch_dtype=dtype,
        safety_checker=None,
    )
    pipe = pipe.to(device)
```

Los par√°metros clave son `num_inference_steps=30` (calidad), `guidance_scale=7.5` (adherencia al prompt) y `height/width=512` (resoluci√≥n). Se a√±adi√≥ manejo de errores con try/except para capturar fallos de modelo o GPU.

---

### 4. Generaci√≥n por lotes ‚Äî Lista de prompts

El script `004-lista de peticiones.py` genera m√∫ltiples im√°genes a partir de una lista de prompts. La mejora principal respecto al c√≥digo original es que **el pipeline se carga una sola vez** fuera del bucle, en lugar de recargarlo en cada iteraci√≥n (lo que ahorra minutos de carga).

```python
# 004-lista de peticiones.py ‚Äî l√≠neas 12-17
# Ruta: 101-Ejercicios/004-lista de peticiones.py
lista = [
  'a green dog over green grass',
  'a pink cat over a sofa',
  'a horse running in the forest'
]
```

```python
# 004-lista de peticiones.py ‚Äî l√≠neas 20-29
# Ruta: 101-Ejercicios/004-lista de peticiones.py
# --- Cargar el pipeline UNA sola vez (mejora de rendimiento) ---
device = "cuda" if torch.cuda.is_available() else "cpu"
dtype = torch.float16 if device == "cuda" else torch.float32

pipe = StableDiffusionPipeline.from_pretrained(
    MODEL_ID,
    torch_dtype=dtype,
    safety_checker=None,
)
pipe = pipe.to(device)
```

Cada imagen se guarda con el nombre del prompt como archivo (ej: `a green dog over green grass.png`). Se a√±adi√≥ progreso visual `[1/3]` y manejo de errores individual por imagen.

---

### 5. Pipeline XML completo ‚Äî Ollama + Stable Diffusion

El script `005-crear imagenes a partir de xml.py` es el m√°s avanzado (349 l√≠neas). Lee un archivo XML de producto (`producto.xml`), extrae contexto sem√°ntico, env√≠a las descripciones de imagen a **Ollama** (modelo LLaMA 3 local) para que genere prompts profesionales de Stable Diffusion, y luego genera todas las im√°genes autom√°ticamente.

```python
# 005-crear imagenes a partir de xml.py ‚Äî l√≠neas 101-133
# Ruta: 101-Ejercicios/005-crear imagenes a partir de xml.py
def build_context_from_xml(root: ET.Element) -> dict:
    """Builds a compact context object from key fields in the XML."""
    title = get_text("./meta/title")
    category = get_text("./meta/category")
    # ... extrae titulo, categoria, propuesta de valor, problemas, beneficios, features
    return {
        "slug": slug,
        "title": title,
        "category": category,
        "valueProposition": value_prop,
        "problems": problems[:8],
        "benefits": benefits[:8],
        "features": features[:10],
        "style": {
            "look": "apple-like, clean, modern SaaS, minimal, premium",
            "avoid": "text, letters, logos, watermarks, UI screenshots with readable text",
        }
    }
```

El flujo es: **XML ‚Üí contexto ‚Üí Ollama genera prompts ‚Üí Stable Diffusion genera im√°genes ‚Üí XML actualizado con rutas locales**.

---

### 6. Generaci√≥n de prompts con Ollama

La funci√≥n `ollama_generate_json` se comunica con un modelo LLaMA 3 local a trav√©s de la API REST de Ollama. Le env√≠a el contexto del producto y la lista de im√°genes, y recibe prompts en ingl√©s optimizados para Stable Diffusion, con negative prompts para evitar texto y logos.

```python
# 005-crear imagenes a partir de xml.py ‚Äî l√≠neas 64-96
# Ruta: 101-Ejercicios/005-crear imagenes a partir de xml.py
def ollama_generate_json(system: str, user: str) -> dict:
    """Asks Ollama to return strict JSON. Retries once if parsing fails."""
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": user,
        "system": system,
        "stream": False,
        "options": {"temperature": 0.4}
    }
    r = requests.post(OLLAMA_URL, json=payload, timeout=OLLAMA_TIMEOUT)
    r.raise_for_status()
    # Retry con temperatura m√°s baja si el JSON no es v√°lido
```

Si Ollama devuelve JSON mal formado, el sistema reintenta autom√°ticamente con temperatura reducida y una instrucci√≥n m√°s estricta (`DEVUELVE SOLO JSON`).

---

### 7. Estructura del XML de producto

El archivo `producto.xml` define la estructura completa de una landing page de producto SaaS educativo ("Gesti√≥n Acad√©mica Pro"). Tiene secciones para hero, problema, soluci√≥n, funcionalidades, p√∫blico objetivo, casos de uso, beneficios, integraciones, confianza, CTA y FAQ, cada una con su propia imagen.

```xml
<!-- producto.xml ‚Äî l√≠neas 1-16 -->
<!-- Ruta: 101-Ejercicios/producto.xml -->
<?xml version="1.0" encoding="UTF-8"?>
<productPage lang="es" type="softwareEducativo" version="1.1">
  <meta>
    <slug>gestion-academica-pro</slug>
    <title>Gesti√≥n Acad√©mica Pro</title>
    <category>SaaS educativo</category>
    <audience>
      <segment>Direcci√≥n</segment>
      <segment>Secretar√≠a / Administraci√≥n</segment>
      <segment>Docentes</segment>
      <segment>Coordinaci√≥n acad√©mica</segment>
    </audience>
  </meta>
```

El XML es el input del pipeline automatizado: cada `<image>` se procesa para generar la imagen correspondiente con IA.

---

### 8. Im√°genes generadas con IA

El directorio `generated_images/` contiene 5 im√°genes generadas autom√°ticamente por el pipeline:

- `hero-gesti√≥n-acad√©mica-moderna.png` ‚Äî imagen principal de la landing
- `problem-problemas-de-gesti√≥n-educativa.png` ‚Äî visualizaci√≥n del problema
- `solution-soluci√≥n-centralizada.png` ‚Äî representaci√≥n de la soluci√≥n
- `features-funcionalidades-clave.png` ‚Äî ilustraci√≥n de funcionalidades
- `audience-p√∫blico-objetivo.png` ‚Äî imagen del p√∫blico objetivo

Cada nombre de archivo se genera autom√°ticamente con la funci√≥n `safe_filename_from_alt()` que combina la secci√≥n + alt text del XML en un slug legible.

---

### 9. Mejoras aplicadas

Se aplicaron mejoras de nivel estudiante sobre los scripts originales:

- **Docstrings** en cada script para documentar el prop√≥sito y requisitos.
- **Manejo de errores** con `try/except` en los scripts 003 y 004 para capturar fallos de modelo o GPU.
- **Pipeline fuera del bucle** en 004: antes se recargaba el modelo entero (~2GB) en cada iteraci√≥n del for; ahora se carga una sola vez.
- **Progreso visual** en 004: mensajes `[1/3] Generando: 'prompt'...` para saber en qu√© imagen va.
- **Constantes configurables** en 003 (`STEPS`, `GUIDANCE`, `IMG_SIZE`, `OUTPUT_FILE`) en lugar de valores hardcoded.
- **Comentarios en espa√±ol** explicando cada secci√≥n del c√≥digo.
- **Tiempo total** en 005: al final del main se muestra el tiempo transcurrido.

---

## Presentaci√≥n del proyecto

Este proyecto muestra un recorrido progresivo por la generaci√≥n de im√°genes con inteligencia artificial. Empezamos instalando Stable Diffusion y su interfaz web, para entender el modelo por fuera. Despu√©s pasamos a controlarlo desde Python con la librer√≠a `diffusers`, generando primero una imagen simple y luego un lote de varias im√°genes.

El ejercicio m√°s avanzado combina dos IAs: Ollama (LLaMA 3) genera los prompts de forma inteligente leyendo un XML de producto, y Stable Diffusion genera las im√°genes correspondientes. El resultado son im√°genes estilo marketing SaaS tipo Apple, creadas autom√°ticamente sin intervenci√≥n manual.

Las im√°genes generadas (en `generated_images/`) demuestran que el pipeline funciona de extremo a extremo: hero, problema, soluci√≥n, funcionalidades y p√∫blico objetivo, todo generado a partir de la descripci√≥n XML del producto.

---

## Conclusi√≥n

Este proyecto demuestra c√≥mo la IA generativa puede automatizar tareas creativas que antes requer√≠an dise√±adores gr√°ficos. La progresi√≥n desde un script b√°sico de una imagen hasta un pipeline completo XML‚ÜíOllama‚ÜíStable Diffusion ilustra conceptos fundamentales: entornos virtuales Python, uso de GPU con CUDA, APIs REST (Ollama), procesamiento XML, y generaci√≥n de im√°genes con modelos de difusi√≥n.

Las mejoras aplicadas ‚Äî extracci√≥n del pipeline fuera del bucle, manejo de errores, documentaci√≥n y constantes configurables ‚Äî dan robustez y claridad al c√≥digo, y demuestran buenas pr√°cticas de programaci√≥n aplicadas a un proyecto de IA.
