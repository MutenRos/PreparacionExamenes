# Proyecto Ollama Curriculums ‚Äî An√°lisis de CVs con IA local

![Proyecto Ollama Curriculums](docs/img/banner.png)

> üîó **GitHub Pages:** [https://mutenros.github.io/Proyecto-intermodular-004-Proyecto-ollama-curriculums/](https://mutenros.github.io/Proyecto-intermodular-004-Proyecto-ollama-curriculums/)

## Introducci√≥n

Este proyecto demuestra c√≥mo utilizar inteligencia artificial local (Ollama con el modelo qwen2.5) para analizar curr√≠culums vitae de forma autom√°tica. El flujo comienza extrayendo texto de un PDF, lo convierte a Markdown y luego lo env√≠a a un modelo LLM que genera un resumen profesional y una valoraci√≥n de idoneidad para un puesto docente. Todo sin depender de APIs externas ni servicios en la nube.

## Desarrollo de las partes

### 1. Extracci√≥n de texto desde PDF

El primer script se encarga de transformar un CV en formato PDF a texto Markdown legible, utilizando las librer√≠as `pypdf` para la extracci√≥n y `markdownify` para la conversi√≥n.

- **Archivo:** `001-Ejercicios/001-procesar curriculum.py`, l√≠neas 8‚Äì39
- **Ruta:** `001-Ejercicios/001-procesar curriculum.py`

```python
def pdf_to_md(path_pdf, path_md):
    if not os.path.isfile(path_pdf):
        print(f"Error: no se encontr√≥ el archivo '{path_pdf}'")
        sys.exit(1)

    reader = PdfReader(path_pdf)
    full_text = ""

    for i, page in enumerate(reader.pages, start=1):
        text = page.extract_text() or ""
        full_text += text + "\n\n"
        print(f"P√°gina {i}/{len(reader.pages)} extra√≠da")

    md_text = md(full_text)

    with open(path_md, "w", encoding="utf-8") as f:
        f.write(md_text)
```

El script recorre cada p√°gina del PDF, acumula el texto y lo guarda como `.md`. Se a√±adi√≥ verificaci√≥n de existencia del archivo y progreso por p√°gina.

### 2. Configuraci√≥n de Ollama y modelo LLM

El segundo script configura la conexi√≥n con Ollama, un servidor local que ejecuta modelos de lenguaje. Se definen constantes para el modelo, el host y el archivo de entrada.

- **Archivo:** `001-Ejercicios/002-procesar md.py`, l√≠neas 1‚Äì15
- **Ruta:** `001-Ejercicios/002-procesar md.py`

```python
ARCHIVO_MD = "CV Jos√© Vicente Carratal√° S√°nchis.md"
MODELO_DEFECTO = "qwen2.5:3b-instruct"
HOST_DEFECTO = "http://localhost:11434"
```

Se usa el modelo `qwen2.5:3b-instruct`, suficientemente ligero para ejecutar en local pero capaz de generar res√∫menes coherentes en espa√±ol.

### 3. Prompt de an√°lisis profesional

El coraz√≥n del proyecto es el prompt que se env√≠a al modelo. Instruye a la IA para actuar como experto en selecci√≥n de personal y generar un resumen profesional del CV, adem√°s de emitir una opini√≥n sobre la idoneidad del candidato.

- **Archivo:** `001-Ejercicios/002-procesar md.py`, l√≠neas 35‚Äì58
- **Ruta:** `001-Ejercicios/002-procesar md.py`

```python
prompt = dedent(f"""
    Eres un experto en selecci√≥n de personal y redacci√≥n de perfiles profesionales.
    
    Tu tarea:
    - Leer el CV cuidadosamente.
    - Identificar habilidades clave, tecnolog√≠as, experiencia relevante y logros.
    - Escribir un resumen profesional conciso en tercera persona.
    - Extensi√≥n orientativa: 7‚Äì10 l√≠neas (m√°ximo ~200 palabras).
    
    -Importante: Emite una opinion acerca de si el perfil es valido o no es v√°lido
     para el puesto de trabajo: profesor de ciclos formativos.

    CV (Markdown):
    ---
    {contenido_md}
    ---
""")
```

### 4. Comunicaci√≥n con la API de Ollama

Se env√≠a el prompt al endpoint `/api/generate` de Ollama mediante una petici√≥n POST con `requests`. La respuesta incluye el resumen generado por la IA.

- **Archivo:** `001-Ejercicios/002-procesar md.py`, l√≠neas 60‚Äì90
- **Ruta:** `001-Ejercicios/002-procesar md.py`

```python
url = f"{host}/api/generate"
payload = {
    "model": modelo.strip(),
    "prompt": prompt,
    "stream": False,
}

response = requests.post(url, json=payload, timeout=600)
response.raise_for_status()
data = response.json()
return data["response"].strip()
```

Se usa `stream: False` para recibir la respuesta completa de una sola vez. El timeout de 600 segundos permite que modelos m√°s pesados completen su respuesta.

### 5. CV de ejemplo: Jos√© Vicente Carratal√°

El proyecto incluye un CV real de 902 l√≠neas convertido a Markdown. Incluye experiencia como profesor de ciclos formativos, CEO de JOCARSA, instructor en LinkedIn Learning y una extensa formaci√≥n en dise√±o industrial, programaci√≥n y gr√°ficos 3D.

- **Archivo:** `001-Ejercicios/CV Jos√© Vicente Carratal√° S√°nchis.md`, l√≠neas 1‚Äì902
- **Ruta:** `001-Ejercicios/CV Jos√© Vicente Carratal√° S√°nchis.md`

El CV cubre experiencia laboral, formaci√≥n acad√©mica, certificaciones, idiomas y habilidades tecnol√≥gicas ‚Äî todo el material que la IA debe procesar.

### 6. Mejoras aplicadas

Se a√±adieron mejoras transversales en ambos scripts:

- **Docstrings** con formato Google en la funci√≥n `pdf_to_md`.
- **Verificaci√≥n de archivo** con `os.path.isfile()` antes de procesarlo.
- **Progreso por p√°gina** al extraer el PDF.
- **`argparse`** para poder pasar el archivo y modelo por l√≠nea de comandos.
- **Errores espec√≠ficos:** `ConnectionError` si Ollama no est√° corriendo, `Timeout` si tarda demasiado.
- **Timing:** muestra cu√°ntos segundos tard√≥ la IA en responder.
- **Constantes en el encabezado** para modelo y host.

## Presentaci√≥n del proyecto

El proyecto **Ollama Curriculums** combina dos tecnolog√≠as: el procesamiento de documentos PDF y la inteligencia artificial local con modelos LLM. El pipeline funciona en dos fases:

1. **Fase de extracci√≥n:** El primer script toma un CV en PDF, extrae el texto de cada p√°gina con `pypdf` y lo convierte a Markdown. Esto normaliza el contenido para que la IA pueda leerlo.

2. **Fase de an√°lisis:** El segundo script carga el Markdown, construye un prompt especializado en selecci√≥n de personal y lo env√≠a a Ollama. El modelo devuelve un resumen profesional y una valoraci√≥n de idoneidad para el puesto de profesor de ciclos formativos.

Lo m√°s interesante del proyecto es que toda la inteligencia artificial se ejecuta en local ‚Äî no se env√≠an datos a ning√∫n servidor externo. Esto garantiza la privacidad del CV procesado, algo fundamental cuando se trabaja con datos personales.

El CV de ejemplo es el del propio profesor, Jos√© Vicente Carratal√°, con m√°s de 20 a√±os de experiencia en docencia, programaci√≥n y dise√±o 3D.

## Conclusi√≥n

Este proyecto muestra c√≥mo la inteligencia artificial local puede integrarse en flujos de trabajo reales de una forma sencilla y respetuosa con la privacidad. Con apenas dos scripts de Python y un servidor Ollama, se consigue automatizar el an√°lisis de curr√≠culums, una tarea que normalmente requiere tiempo y criterio humano. La progresi√≥n del proyecto ‚Äî primero extraer, luego analizar ‚Äî refleja un enfoque modular y escalable que podr√≠a ampliarse con m√°s modelos, m√°s formatos de entrada o una interfaz web.
