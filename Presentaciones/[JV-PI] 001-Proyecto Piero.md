# Proyecto Piero ‚Äî Web Scraping e Im√°genes con Python

![Proyecto Piero](docs/img/banner.png)

> üîó **GitHub Pages:** [https://mutenros.github.io/Proyecto-intermodular-001-Proyecto-Piero/](https://mutenros.github.io/Proyecto-intermodular-001-Proyecto-Piero/)

## Introducci√≥n

Este proyecto recorre paso a paso el camino desde una simple petici√≥n HTTP hasta un scraper completo de Google Images con sesiones, cabeceras realistas y descarga masiva de ficheros. Cada iteraci√≥n del c√≥digo a√±ade una capa nueva de complejidad, lo que permite entender c√≥mo funcionan las peticiones web, el an√°lisis de HTML y la automatizaci√≥n de descargas de recursos multimedia.

## Desarrollo de las partes

### 1. Primeros pasos con `requests`

El punto de partida es importar la librer√≠a `requests`, la herramienta est√°ndar de Python para realizar peticiones HTTP. En esta fase se comprueba que el entorno est√° listo.

```python
import requests
```

Este primer fichero sirve como prueba de concepto m√≠nima: si el import funciona, el entorno tiene las dependencias necesarias.

### 2. Petici√≥n GET a una web propia

Se realiza una petici√≥n GET a `jocarsa.com` para obtener el c√≥digo HTML completo de la p√°gina. Se imprime el c√≥digo de estado y el contenido.

```python
url = "https://jocarsa.com"
response = requests.get(url, headers=HEADERS, timeout=10)
response.raise_for_status()
print("Status:", response.status_code)
print("Encoding:", response.encoding)
html = response.text
```

Se a√±adieron cabeceras User-Agent y manejo de errores con `try/except` para capturar fallos de conexi√≥n, timeout y errores HTTP.

### 3. Scraper de im√°genes desde una web

Se extrae autom√°ticamente cada imagen de `jocarsa.com` utilizando dos t√©cnicas complementarias:

- **Etiquetas `<img>`:** BeautifulSoup recorre el DOM buscando atributos `src`.
- **CSS `background-image`:** Se aplica una expresi√≥n regular sobre los atributos `style` para capturar URLs en `background-image:url(...)`.

```python
for img in soup.find_all("img"):
    src = img.get("src")
    if src:
        full_url = urljoin(URL, src)
        image_urls.add(full_url)

pattern = re.compile(
    r"background-image\s*:\s*url\(['\"]?(.*?)['\"]?\)",
    re.IGNORECASE
)
```

Las im√°genes se descargan en la carpeta `imagenes/` con gesti√≥n de nombres duplicados y control de errores.

### 4. Scraping de Google Images

Se adapta el scraper anterior para buscar im√°genes en Google. La URL de b√∫squeda se simplific√≥ eliminando par√°metros ef√≠meros y dejando solo los esenciales (`q`, `tbm`).

```python
SEARCH_QUERY = "ardilla"
URL = f"https://www.google.com/search?q={SEARCH_QUERY}&tbm=isch&hl=es"
```

Se a√±adi√≥ User-Agent y timeout para evitar bloqueos por parte de Google.

### 5. Scraper avanzado con sesiones y m√∫ltiples m√©todos

Esta iteraci√≥n supone un salto cualitativo importante:

| Caracter√≠stica | Detalle |
|---|---|
| **Sesiones** | `requests.Session()` mantiene cookies entre peticiones |
| **Cabeceras completas** | User-Agent, Accept, DNT, etc. |
| **Retardos aleatorios** | `time.sleep(random.uniform(2, 5))` para evitar detecci√≥n |
| **Tres m√©todos de extracci√≥n** | Etiquetas `<img>`, URLs dentro de `<script>` y base64 |
| **Paginaci√≥n** | Se avanza por p√°ginas de resultados de forma autom√°tica |
| **Descarga con streaming** | `iter_content(chunk_size=8192)` para ficheros grandes |

```python
session = requests.Session()
session.headers.update(HEADERS)

# M√©todo 1: img tags
# M√©todo 2: URLs en scripts JSON
# M√©todo 3: base64 en data attributes
```

### 6. Par√°metro personalizado por el usuario

La √∫ltima iteraci√≥n permite al usuario introducir el t√©rmino de b√∫squeda por consola. Se a√±adi√≥ validaci√≥n de entrada para rechazar cadenas vac√≠as.

```python
SEARCH_QUERY = input("Introduce el termino que quieres buscar: ").strip()
if not SEARCH_QUERY:
    print("Error: debes introducir un t√©rmino de b√∫squeda.")
    exit(1)
```

### 7. Mejoras transversales aplicadas

En todas las iteraciones se aplicaron mejoras de calidad:

- **Cabeceras User-Agent** para evitar bloqueos del servidor.
- **Timeout** en todas las peticiones para evitar bloqueos infinitos.
- **Try/except** con tipos de excepci√≥n espec√≠ficos (`ConnectionError`, `Timeout`, `HTTPError`).
- **Validaci√≥n de input** en la versi√≥n interactiva.
- **Limpieza de la URL de Google** eliminando par√°metros ef√≠meros y tokens.

## Presentaci√≥n del proyecto

El proyecto **Piero** demuestra una progresi√≥n did√°ctica completa del web scraping en Python. Se parte de la operaci√≥n m√°s b√°sica ‚Äî importar una librer√≠a ‚Äî y se llega hasta un sistema de descarga masiva de im√°genes desde Google con t√©cnicas anti-detecci√≥n.

El pipeline completo funciona de la siguiente manera:

1. El usuario ejecuta el script y opcionalmente introduce un t√©rmino de b√∫squeda.
2. El programa construye la URL de Google Images y env√≠a la petici√≥n con cabeceras realistas.
3. BeautifulSoup analiza el HTML devuelto y extrae URLs de im√°genes por tres v√≠as diferentes.
4. Cada imagen se descarga de forma secuencial con retardos aleatorios, se valida su tipo MIME y se guarda en disco con un nombre limpio.

Las carpetas `imagenes/` y `google_images/` contienen los resultados reales de las ejecuciones: desde los recursos de `jocarsa.com` hasta fotograf√≠as de ardillas obtenidas de Google.

## Conclusi√≥n

Este proyecto muestra c√≥mo una funcionalidad aparentemente simple ‚Äî descargar im√°genes de internet ‚Äî requiere en realidad un conocimiento profundo de HTTP, parsing HTML, expresiones regulares y buenas pr√°cticas de programaci√≥n defensiva. Cada iteraci√≥n introduce un concepto nuevo (sesiones, headers, base64, streaming, validaci√≥n) que se acumula sobre lo anterior, formando un aprendizaje incremental y s√≥lido. El resultado final es un scraper funcional, robusto y configurable que puede adaptarse a cualquier t√©rmino de b√∫squeda.
